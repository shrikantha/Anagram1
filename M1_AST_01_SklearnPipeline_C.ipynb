{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shrikantha/Anagram1/blob/master/M1_AST_01_SklearnPipeline_C.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E7f_QYB9HwEt"
      },
      "source": [
        "# Advanced Certification Programme in AI and MLOps\n",
        "## A programme by IISc and TalentSprint\n",
        "### Assignment 1: Pipeline Optimization with Scikit-Learn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "93OhtrPFI3Cv"
      },
      "source": [
        "## Learning Objectives"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VCt0SUxASryl"
      },
      "source": [
        "At the end of the experiment, you will be able to:\n",
        "\n",
        "- appreciate the significance of a pipeline and its optimization\n",
        "- setup a machine learning pipeline\n",
        "- optimize the pipeline\n",
        "- know techniques to analyze the results of optimization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X5uhFSfxJppc"
      },
      "source": [
        "## Information"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fhtMbxlbSZOc"
      },
      "source": [
        "A machine learning pipeline can be created by putting together a sequence of steps involved in training a machine learning model. It can be used to automate a machine learning workflow. The pipeline can involve pre-processing, feature selection, classification/regression, and post-processing steps. More complex applications may need to fit in other necessary steps within this pipeline."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6eC1QBzs1OZO"
      },
      "source": [
        "Substances in traditional fire-extinguishing techniques may leave chemical waste, harm human health and cause social and economic damages. Therefore research on fire-extinguishing using renewable energy sources is important. The impact of sound waves on flame and combustion behavior of fuel is a common.\n",
        "\n",
        "Fire is a chemical reaction that breaks out with the combination of heat, fuel, and oxygen components. The heat, gas, and smoke resulting from this oxidation reaction may significantly harm to human and the environment. Early intervention to the fire facilitates to extinguish. However, depending on the scale of the fire and the fuel type, fire-extinguishing agents may vary. These substances in traditional fire-extinguishing techniques may leave chemical waste and harm human health. Additionally, it can also cause social and economic damages. In order to eliminate these impacts, researches on fire-extinguishing with renewable energy sources have been carried out. Currently, the impact of sound waves on flame and combustion behavior of fuel is a common research topic. The pressure changes in the air as a result of the sound waves lead to the occurrence of airflow. This airflow changes the behavior of the flame, fuel, and oxygen in the environment. The airflow created by the sound waves enables the fuel to spread over a wider surface. At this phase, the flame shows the tendency of spreading over a wide area together with the fuel. Fuel consumption also increases by the fuel particle oscillation due to the spread of flame and sound waves. While these stages are taking place, the air in the fire environment mixes and the amount of oxygen decreases as a result of the compression and expansion movements in the air. Through the combination of these three events, the flame can be extinguished. Necessary frequency ranges are available for the flame to be extinguished with the sound waves. Besides the frequency characteristic of sound waves, sound intensity level and the distance are also the factors having an impact on the ability to extinguish the flame.\n",
        "\n",
        "Utilizing the fire characteristics, studies have been carried out to estimate the parameters necessary for the detection and extinguishing of the fire. The data have been obtained by examining the characteristics of the flames extinguished using sound waves. Statistical analysis and classification algorithms using these data provide information on the behaviour of the flame.\n",
        "\n",
        "\n",
        "To know more about the experiment, click [here](https://ieeexplore.ieee.org/document/9452168)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hk4BqqzecR1K"
      },
      "source": [
        "## Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NuMzOs9LJ6zk"
      },
      "source": [
        "The dataset was obtained as a result of the extinguishing tests of four different fuel flames with a sound wave extinguishing system. The sound wave fire-extinguishing system consists of 4 subwoofers with a total power of 4,000 Watt placed in the collimator cabinet. There are two amplifiers that enable the sound come to these subwoofers as boosted. Power supply that powers the system and filter circuit ensuring that the sound frequencies are properly transmitted to the system is located within the control unit. While computer is used as frequency source, anemometer was used to measure the airflow resulted from sound waves during the extinguishing phase of the flame, and a decibel meter to measure the sound intensity. An infrared thermometer was used to measure the temperature of the flame and the fuel can, and a camera is installed to detect the extinction time of the flame. A total of 17,442 tests were conducted with this experimental setup.\n",
        "\n",
        "The experiments are planned as follows:\n",
        "\n",
        "- Three different liquid fuels and LPG fuel were used to create the flame.\n",
        "- 5 different sizes of liquid fuel cans are used to achieve different size of flames.\n",
        "- Half and full gas adjustment is used for LPG fuel.\n",
        "- While carrying out each experiment, the fuel container, at 10 cm distance, was moved forward up to 190 cm by increasing the distance by 10 cm each time.\n",
        "- Along with the fuel container, anemometer and decibel meter were moved forward in the same dimensions.\n",
        "- Fire extinguishing experiments was conducted with 54 different frequency sound waves at each distance and flame size.\n",
        "Throughout the flame extinguishing experiments, the data obtained from each measurement device was recorded and a dataset was created.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aO4pFGacmA0S"
      },
      "source": [
        "The dataset includes following features:\n",
        "\n",
        "- **SIZE:** *fuel container size representing the flame size*\n",
        "- **FUEL:** *fuel type*\n",
        "- **FREQUENCY**\n",
        "- **DECIBEL**\n",
        "- **DISTANCE**\n",
        "- **AIRFLOW**\n",
        "- **STATUS:** *flame extinction (dependent/target variable)*\n",
        "\n",
        "Accordingly, 6 input features and 1 output feature will be used in models. The explanation of a total of seven features for liquid fuels in the dataset is given in Table 1, and the explanation of 7 features for LPG fuel is given in Table 2.\n",
        "The status property (flame extinction or non-extinction states) can be predicted by using six features in the dataset. Status and fuel features are categorical, while other features are numerical. 8,759 of the 17,442 test results are the non-extinguishing state of the flame. 8,683 of them are the extinction state of the flame. According to these numbers, it can be said that the class distribution of the dataset is almost equal.\"\n",
        "\n",
        "To know more about the dataset, click [here](https://www.kaggle.com/datasets/muratkokludataset/acoustic-extinguisher-fire-dataset)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BNLA8HiKxQhc"
      },
      "source": [
        "### Setup Steps:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gNmNyXQqsiTD"
      },
      "source": [
        "#@title Please enter your registration id to start: { run: \"auto\", display-mode: \"form\" }\n",
        "Id = \"\" #@param {type:\"string\"}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ekXeY2KFsiTE"
      },
      "source": [
        "#@title Please enter your password (your registered phone number) to continue: { run: \"auto\", display-mode: \"form\" }\n",
        "password = \"\" #@param {type:\"string\"}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "JNyWLItTsiTF"
      },
      "source": [
        "#@title Run this cell to complete the setup for this Notebook\n",
        "from IPython import get_ipython\n",
        "\n",
        "ipython = get_ipython()\n",
        "\n",
        "notebook= \"M1_AST_01_SklearnPipeline_C\" #name of the notebook\n",
        "\n",
        "def setup():\n",
        "#  ipython.magic(\"sx pip3 install torch\")\n",
        "\n",
        "    ipython.magic(\"sx wget https://cdn.iisc.talentsprint.com/AIandMLOps/Datasets/Acoustic_Extinguisher_Fire_Dataset.xlsx\")\n",
        "    from IPython.display import HTML, display\n",
        "    display(HTML('<script src=\"https://dashboard.talentsprint.com/aiml/record_ip.html?traineeId={0}&recordId={1}\"></script>'.format(getId(),submission_id)))\n",
        "    print(\"Setup completed successfully\")\n",
        "    return\n",
        "\n",
        "def submit_notebook():\n",
        "    ipython.magic(\"notebook -e \"+ notebook + \".ipynb\")\n",
        "\n",
        "    import requests, json, base64, datetime\n",
        "\n",
        "    url = \"https://dashboard.talentsprint.com/xp/app/save_notebook_attempts\"\n",
        "    if not submission_id:\n",
        "      data = {\"id\" : getId(), \"notebook\" : notebook, \"mobile\" : getPassword()}\n",
        "      r = requests.post(url, data = data)\n",
        "      r = json.loads(r.text)\n",
        "\n",
        "      if r[\"status\"] == \"Success\":\n",
        "          return r[\"record_id\"]\n",
        "      elif \"err\" in r:\n",
        "        print(r[\"err\"])\n",
        "        return None\n",
        "      else:\n",
        "        print (\"Something is wrong, the notebook will not be submitted for grading\")\n",
        "        return None\n",
        "\n",
        "    elif getAnswer() and getComplexity() and getAdditional() and getConcepts() and getComments() and getMentorSupport():\n",
        "      f = open(notebook + \".ipynb\", \"rb\")\n",
        "      file_hash = base64.b64encode(f.read())\n",
        "\n",
        "      data = {\"complexity\" : Complexity, \"additional\" :Additional,\n",
        "              \"concepts\" : Concepts, \"record_id\" : submission_id,\n",
        "              \"answer\" : Answer, \"id\" : Id, \"file_hash\" : file_hash,\n",
        "              \"notebook\" : notebook,\n",
        "              \"feedback_experiments_input\" : Comments,\n",
        "              \"feedback_mentor_support\": Mentor_support}\n",
        "      r = requests.post(url, data = data)\n",
        "      r = json.loads(r.text)\n",
        "      if \"err\" in r:\n",
        "        print(r[\"err\"])\n",
        "        return None\n",
        "      else:\n",
        "        print(\"Your submission is successful.\")\n",
        "        print(\"Ref Id:\", submission_id)\n",
        "        print(\"Date of submission: \", r[\"date\"])\n",
        "        print(\"Time of submission: \", r[\"time\"])\n",
        "        print(\"View your submissions: https://aimlops-iisc.talentsprint.com/notebook_submissions\")\n",
        "        #print(\"For any queries/discrepancies, please connect with mentors through the chat icon in LMS dashboard.\")\n",
        "        return submission_id\n",
        "    else: submission_id\n",
        "\n",
        "\n",
        "def getAdditional():\n",
        "  try:\n",
        "    if not Additional:\n",
        "      raise NameError\n",
        "    else:\n",
        "      return Additional\n",
        "  except NameError:\n",
        "    print (\"Please answer Additional Question\")\n",
        "    return None\n",
        "\n",
        "def getComplexity():\n",
        "  try:\n",
        "    if not Complexity:\n",
        "      raise NameError\n",
        "    else:\n",
        "      return Complexity\n",
        "  except NameError:\n",
        "    print (\"Please answer Complexity Question\")\n",
        "    return None\n",
        "\n",
        "def getConcepts():\n",
        "  try:\n",
        "    if not Concepts:\n",
        "      raise NameError\n",
        "    else:\n",
        "      return Concepts\n",
        "  except NameError:\n",
        "    print (\"Please answer Concepts Question\")\n",
        "    return None\n",
        "\n",
        "\n",
        "# def getWalkthrough():\n",
        "#   try:\n",
        "#     if not Walkthrough:\n",
        "#       raise NameError\n",
        "#     else:\n",
        "#       return Walkthrough\n",
        "#   except NameError:\n",
        "#     print (\"Please answer Walkthrough Question\")\n",
        "#     return None\n",
        "\n",
        "def getComments():\n",
        "  try:\n",
        "    if not Comments:\n",
        "      raise NameError\n",
        "    else:\n",
        "      return Comments\n",
        "  except NameError:\n",
        "    print (\"Please answer Comments Question\")\n",
        "    return None\n",
        "\n",
        "\n",
        "def getMentorSupport():\n",
        "  try:\n",
        "    if not Mentor_support:\n",
        "      raise NameError\n",
        "    else:\n",
        "      return Mentor_support\n",
        "  except NameError:\n",
        "    print (\"Please answer Mentor support Question\")\n",
        "    return None\n",
        "\n",
        "def getAnswer():\n",
        "  try:\n",
        "    if not Answer:\n",
        "      raise NameError\n",
        "    else:\n",
        "      return Answer\n",
        "  except NameError:\n",
        "    print (\"Please answer Question\")\n",
        "    return None\n",
        "\n",
        "\n",
        "def getId():\n",
        "  try:\n",
        "    return Id if Id else None\n",
        "  except NameError:\n",
        "    return None\n",
        "\n",
        "def getPassword():\n",
        "  try:\n",
        "    return password if password else None\n",
        "  except NameError:\n",
        "    return None\n",
        "\n",
        "submission_id = None\n",
        "### Setup\n",
        "if getPassword() and getId():\n",
        "  submission_id = submit_notebook()\n",
        "  if submission_id:\n",
        "    setup()\n",
        "else:\n",
        "  print (\"Please complete Id and Password cells before running setup\")\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "69RDKc0Rq6Le"
      },
      "source": [
        "### Import Required Packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "88_C4BgAFCH2"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt                                 # For plotting data\n",
        "import seaborn as sns                                           # For plotting data\n",
        "from sklearn.model_selection import train_test_split            # For train/test splits\n",
        "from sklearn.neighbors import KNeighborsClassifier              # The k-nearest neighbor classifier\n",
        "from sklearn.feature_selection import VarianceThreshold         # Feature selector\n",
        "from sklearn.pipeline import Pipeline                           # For setting up pipeline\n",
        "\n",
        "# Various pre-processing steps\n",
        "from sklearn.preprocessing import Normalizer, StandardScaler, MinMaxScaler, PowerTransformer, MaxAbsScaler, LabelEncoder, OrdinalEncoder\n",
        "from sklearn.model_selection import GridSearchCV                # For optimization\n",
        "\n",
        "# To supress warnings\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "49YbZU_erJn4"
      },
      "source": [
        "### Load the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "69at-tNsTDcC"
      },
      "outputs": [],
      "source": [
        "df = pd.read_excel('Acoustic_Extinguisher_Fire_Dataset.xlsx', sheet_name='A_E_Fire_Dataset')\n",
        "# Shape of dataframe\n",
        "df.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H53GhbkwrQMw"
      },
      "source": [
        "### Data Exploration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oefdmDE_UiCc"
      },
      "outputs": [],
      "source": [
        "# Show first few rows of dataframe\n",
        "df.head(8)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PVIuNmCPsDNn"
      },
      "source": [
        "From above it can be seen that:\n",
        "\n",
        "- There are 6 independent variables\n",
        "- `FUEL` is a categorical feature\n",
        "- Every other feature is numerical\n",
        "- `STATUS` is the dependent variable\n",
        "- It is a binary classification problem"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ot-_opHsraf"
      },
      "source": [
        "### Segregating the dataframe into independent and dependent features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4xcV5GOXcDT7"
      },
      "outputs": [],
      "source": [
        "# The data matrix X\n",
        "X = df.iloc[:, :-1]\n",
        "# The labels\n",
        "y = (df.iloc[:,-1:])\n",
        "\n",
        "X.shape, y.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GHGQcdQAdth6"
      },
      "outputs": [],
      "source": [
        "# Independent features\n",
        "X"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ifhK8xQhtC2N"
      },
      "source": [
        "### Exploring the unique categories in categorical feature"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K4r1aHQtfibA"
      },
      "outputs": [],
      "source": [
        "# Unique values in FUEL column\n",
        "X['FUEL'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9tPMhs0YvnAP"
      },
      "outputs": [],
      "source": [
        "# Plot unique values in FUEL column\n",
        "uniques = X['FUEL'].value_counts()\n",
        "sns.barplot(x = uniques.index, y = uniques.values)\n",
        "plt.xlabel(\"FUEL type\")\n",
        "plt.ylabel(\"Values\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CMhEIvL-kCSA"
      },
      "source": [
        "### Encoding the Categorical Feature"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nLEf_IV8kAEW"
      },
      "outputs": [],
      "source": [
        "# Ordinal encode input variable\n",
        "ordinal = OrdinalEncoder()\n",
        "X['FUEL'] = ordinal.fit_transform(X[['FUEL']])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VDEmTnxG0Dvh"
      },
      "outputs": [],
      "source": [
        "X.tail(110)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "REdtfeKftWr1"
      },
      "source": [
        "After ordinal encoding, all the features are numerical in nature now."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4cUIcML23n-L"
      },
      "outputs": [],
      "source": [
        "# Prediction features\n",
        "X.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7qdzBidudvYk"
      },
      "outputs": [],
      "source": [
        "# Target feature: Extinction Status\n",
        "y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sxH87eA-tgZT"
      },
      "source": [
        "### Split the data into train and test sets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4y-f5vXOdxtN"
      },
      "outputs": [],
      "source": [
        "# Split the data into train and test\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,                  # predictors\n",
        "                                                    y,                  # labels\n",
        "                                                    test_size=1/3,      # test set size\n",
        "                                                    random_state=0)     # set random number generator seed for reproducibility\n",
        "\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "81xxistBUov5"
      },
      "source": [
        "### A Classifier Without a Pipeline and Optimization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MxxfOS4W_gJZ"
      },
      "source": [
        "First, let’s just check how the k-nearest neighbor performs on the training and test sets. This would give us a baseline for performance.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dnUXK9waUSeI"
      },
      "outputs": [],
      "source": [
        "# Instantiate KNN classifier and fit on train set\n",
        "knn = KNeighborsClassifier().fit(X_train, y_train)\n",
        "\n",
        "# Performance on train and test sets\n",
        "print('Training set score: ' + str(knn.score(X_train,y_train)))\n",
        "print('Test set score: ' + str(knn.score(X_test,y_test)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iJ0JCvWsU7-e"
      },
      "source": [
        "### Setting Up a Machine Learning Pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LLeFDVre_SZS"
      },
      "source": [
        "- **Scaler:** For pre-processing data, i.e., transform the data to zero mean and unit variance using the `StandardScaler()`.\n",
        "\n",
        "- **Feature selector:** Use `VarianceThreshold()` for discarding features whose variance is less than a certain defined threshold.\n",
        "\n",
        "- **Classifier:** `KNeighborsClassifier()`, which implements the k-nearest neighbor classifier and selects the class of the majority k points, which are closest to the test example."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hoXhOD7HUv8m"
      },
      "outputs": [],
      "source": [
        "# Setup pipeline\n",
        "pipe = Pipeline([('scaler', StandardScaler()),\n",
        "                 ('selector', VarianceThreshold()),\n",
        "                 ('classifier', KNeighborsClassifier())\n",
        "                 ])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E_3WR3shVGsb"
      },
      "outputs": [],
      "source": [
        "# Fit pipeline on train set\n",
        "pipe.fit(X_train, y_train)\n",
        "\n",
        "# Performance on train and test sets\n",
        "print('Training set score: ' + str(pipe.score(X_train,y_train)))\n",
        "print('Test set score: ' + str(pipe.score(X_test,y_test)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "le5Pzs4Rt4oA"
      },
      "source": [
        "It can be clearly noticed that setting the pipeline, including `StandardScaler()` and `VarianceThreshold()` has helped train a good model because scores are better both for training and test data when compared with the model without using a pipeline."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fowNWKfFVTx_"
      },
      "source": [
        "### Optimizing and Tuning the Pipeline with GridSearchCV"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LLDvhYpwnNFw"
      },
      "source": [
        "In the code below, we’ll show the following:\n",
        "\n",
        "- We can search for the best scalers. Instead of just the `StandardScaler()`, we can try `MinMaxScaler()`, `Normalizer()`, and `MaxAbsScaler()`.\n",
        "\n",
        "- We can search for the best variance threshold to use in the selector, i.e., `VarianceThreshold()`.\n",
        "\n",
        "- We can search for the best value of k for the `KNeighborsClassifier()`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4K5_Y-egVKuv"
      },
      "outputs": [],
      "source": [
        "parameters = {'scaler': [StandardScaler(), MinMaxScaler(), Normalizer(), MaxAbsScaler()],\n",
        "              'selector__threshold': [0, 0.001, 0.01],\n",
        "\t\t\t  'classifier__n_neighbors': [1, 3, 5, 7, 10],           # Number of neighbors to use by default for k-neighbors\n",
        "\t\t\t  'classifier__p': [1, 2],                               # Power parameter for the Minkowski metric\n",
        "\t\t\t  'classifier__leaf_size': [1, 5, 10, 15]                # Leaf size passed to BallTree or KDTree. This can affect the speed of the\n",
        "\t\t\t  }                                                      # construction and query, as well as the memory required to store the tree"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YKdKGlTbeW9I"
      },
      "outputs": [],
      "source": [
        "4*3*5*2*4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mdtg8rcU_nEa"
      },
      "source": [
        "Here, we have passed a list of parameters that the GridsearchCV algorithm will use to come at an optimum solution. It will go through every combination of this parameters to get an optimal solution. So, total iterations here will be 4 $\\times$ 3 $\\times$ 5 $\\times$ 2 $\\times$ 4 = 480.\n",
        "\n",
        "`n_neighbors`, `p` and `leaf_size` are the parameter for `KNeighborsClassifier()`.\n",
        "\n",
        "To know more about `KNeighborsClassifier()`, refer [here](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html#sklearn.neighbors.KNeighborsClassifier)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XlUHH0bZnRqF"
      },
      "outputs": [],
      "source": [
        "# Instantiate GridSearchCV\n",
        "grid = GridSearchCV(pipe, parameters, cv=2).fit(X_train, y_train)\n",
        "\n",
        "# Performance on train and test sets\n",
        "print('Training set score: ' + str(grid.score(X_train, y_train)))\n",
        "print('Test set score: ' + str(grid.score(X_test, y_test)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JCnKM224AIMm"
      },
      "source": [
        "To know more about GridSearchCV, refer [here](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html#sklearn.model_selection.GridSearchCV)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-zNZEXAFo3a2"
      },
      "source": [
        "### Analyzing the Results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-q9LPWF8nXSS"
      },
      "outputs": [],
      "source": [
        "# Access the best set of parameters\n",
        "best_params = grid.best_params_\n",
        "print(best_params)\n",
        "\n",
        "# Stores the optimum model in best_pipe\n",
        "best_pipe = grid.best_estimator_\n",
        "print(best_pipe)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VbarYPUJif0z"
      },
      "source": [
        "Another useful technique for analyzing the results is to construct a DataFrame from the `grid.cv_results_` attribute."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IJiM_ZhEo9pt"
      },
      "outputs": [],
      "source": [
        "# Create a dataframe\n",
        "result_df = pd.DataFrame.from_dict(grid.cv_results_, orient='columns')\n",
        "print(result_df.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oYYRy9QQc3vK"
      },
      "outputs": [],
      "source": [
        "result_df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZiJHUyPTczoj"
      },
      "outputs": [],
      "source": [
        "result_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cGRrwxgACPJW"
      },
      "source": [
        "This DataFrame is very valuable as it shows us the scores for different parameters. The column with the `mean_test_score` is the average of the scores on the test set for all the folds during cross-validation. The DataFrame may be too big to visualize manually, hence, it is always a good idea to plot the results.\n",
        "\n",
        "Let’s see how `n_neighbors` affect the performance for different `scalers`, and for different values of `p`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T5YjM-2Lpw8y"
      },
      "outputs": [],
      "source": [
        "sns.relplot(data = result_df,\n",
        "            kind = 'line',\n",
        "\t\t\tx = 'param_classifier__n_neighbors',\n",
        "\t\t\ty = 'mean_test_score',\n",
        "\t\t\thue = 'param_scaler',\n",
        "\t\t\tcol = 'param_classifier__p')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4UFZTncnDBDb"
      },
      "source": [
        "From the above plots, it can be seen that:\n",
        "\n",
        "- For both `p = 1` and `2`, worst performing scaler method is `Normalizer()`\n",
        "- For both `p = 1` and `2`, best performing scaler is `MaxAbsScaler()`\n",
        "- For `p = 1` and `scaler = MaxAbsScaler()`, there is a peak in `mean_test_score` at `n_neighbors = 5`.\n",
        "\n",
        "Let’s see how `n_neighbors` affect the performance for different `scalers`, and for different values of `life_size`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VB9NpUkRqi58"
      },
      "outputs": [],
      "source": [
        "sns.relplot(data = result_df,\n",
        "            kind = 'line',\n",
        "            x = 'param_classifier__n_neighbors',\n",
        "            y = 'mean_test_score',\n",
        "            hue = 'param_scaler',\n",
        "            col = 'param_classifier__leaf_size')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CAZD73LSDw3q"
      },
      "source": [
        "- For all the `leaf_size` parameters, that is 1, 5, 10, 15, worst performing scaler method is `Normalizer()`.\n",
        "- For all the `leaf_size` parameters, best performing scaler is `MaxAbsScaler()`.\n",
        "- For all the `leaf_size` parameters, there is a peak at `n_neighbors = 5`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p1fpVuU87D0i"
      },
      "source": [
        "`MaxAbsScaler()` is performing well because it scales and translates each feature individually such that the maximal absolute value of each feature in the training set will be $1.0$. It does not shift or center the data, and thus does not destroy any sparsity.\n",
        "\n",
        "To know more about `MaxAbsScaler()`, refer [here](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MaxAbsScaler.html#sklearn.preprocessing.MaxAbsScaler)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VHfHdGCP_n6Y"
      },
      "source": [
        "### Please answer the questions below to complete the experiment:\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VgSwVENIPcM6"
      },
      "outputs": [],
      "source": [
        "#@title Select the False statement regarding Scikit-learn Pipeline: { run: \"auto\", form-width: \"500px\", display-mode: \"form\" }\n",
        "Answer = \"\" #@param [\"\", \"With pipeline, all the preprocessing steps needs to be done separately for both training and testing set\", \"Without pipeline, the parameters used for preprocessing of training set needs to be stored for preprocessing testing set\", \"With pipeline, doing the same preprocessing steps twice can be avoided\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NMzKSbLIgFzQ"
      },
      "outputs": [],
      "source": [
        "#@title How was the experiment? { run: \"auto\", form-width: \"500px\", display-mode: \"form\" }\n",
        "Complexity = \"\" #@param [\"\",\"Too Simple, I am wasting time\", \"Good, But Not Challenging for me\", \"Good and Challenging for me\", \"Was Tough, but I did it\", \"Too Difficult for me\"]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DjcH1VWSFI2l"
      },
      "outputs": [],
      "source": [
        "#@title If it was too easy, what more would you have liked to be added? If it was very difficult, what would you have liked to have been removed? { run: \"auto\", display-mode: \"form\" }\n",
        "Additional = \"\" #@param {type:\"string\"}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4VBk_4VTAxCM"
      },
      "outputs": [],
      "source": [
        "#@title Can you identify the concepts from the lecture which this experiment covered? { run: \"auto\", vertical-output: true, display-mode: \"form\" }\n",
        "Concepts = \"\" #@param [\"\",\"Yes\", \"No\"]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XH91cL1JWH7m"
      },
      "outputs": [],
      "source": [
        "#@title  Text and image description/explanation and code comments within the experiment: { run: \"auto\", vertical-output: true, display-mode: \"form\" }\n",
        "Comments = \"\" #@param [\"\",\"Very Useful\", \"Somewhat Useful\", \"Not Useful\", \"Didn't use\"]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z8xLqj7VWIKW"
      },
      "outputs": [],
      "source": [
        "#@title Mentor Support: { run: \"auto\", vertical-output: true, display-mode: \"form\" }\n",
        "Mentor_support = \"\" #@param [\"\",\"Very Useful\", \"Somewhat Useful\", \"Not Useful\", \"Didn't use\"]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "FzAZHt1zw-Y-"
      },
      "outputs": [],
      "source": [
        "#@title Run this cell to submit your notebook for grading { vertical-output: true }\n",
        "try:\n",
        "  if submission_id:\n",
        "      return_id = submit_notebook()\n",
        "      if return_id : submission_id = return_id\n",
        "  else:\n",
        "      print(\"Please complete the setup first.\")\n",
        "except NameError:\n",
        "  print (\"Please complete the setup first.\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}